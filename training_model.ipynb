{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.autograd import Variable\n",
        "from math import pi\n",
        "import random\n",
        "import numpy as np\n",
        "from math import cos, sin"
      ],
      "outputs": [],
      "metadata": {
        "id": "TTvPtGgBepel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Means of Modeling Manipulators\n",
        "\n",
        "To start, the classes \"Manipulator\" and \"Link\" were created that allows the representation of the specifications of manipulators. These classes will be used later on to generate the data required for the manipulators we will train our models to compute the inverse kinematics for. For an instance of this class to be instantiated, the Denavit-Hartenberg (DH) parameters of the manipulator's links will have to be provided. This allows for the forward kinemtics to be computed in order to find the position of the end effector, given the link's angles."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "class Link():\n",
        "    def __init__(self,theta_offset,d,alpha,a):\n",
        "        self.theta_offset = theta_offset\n",
        "        self.d = d\n",
        "        self.alpha = alpha\n",
        "        self.a = a\n",
        "    def get_transformation(self, theta):\n",
        "        theta = theta+self.theta_offset\n",
        "        transformation_matrix = np.array([\n",
        "            [cos(theta), -sin(theta) * cos(self.alpha), sin(theta) * sin(self.alpha), self.a * cos(theta)],\n",
        "            [sin(theta), cos(theta) * cos(self.alpha), -cos(theta) * sin(self.alpha), self.a * sin(theta)],\n",
        "            [0, sin(self.alpha), cos(self.alpha), self.d],\n",
        "            [0, 0, 0, 1]\n",
        "        ])\n",
        "        return transformation_matrix\n",
        "\n",
        "class Manipulator:\n",
        "    def __init__(self, links=None, q=None):\n",
        "        self.links = links if links else []\n",
        "        self.q = q if q else []\n",
        "    \n",
        "    def add_link(self, link):\n",
        "        self.links.append(link)\n",
        "\n",
        "    def forward_kinematics(self, joint_angles):        \n",
        "        transformation_matrix = np.identity(4)\n",
        "        pos = []\n",
        "        for i in range(len(self.links)):\n",
        "            transformation_matrix = np.dot(transformation_matrix, self.links[i].get_transformation(joint_angles[i]))\n",
        "            pos.append([transformation_matrix[0][3],transformation_matrix[1][3]])\n",
        "        return transformation_matrix"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two-Joints Manipulator Continous Path\n",
        "\n",
        "In the second iteration, the aim is to design a neural network capable of determining the **joint angles necessary** for the manipulator to reach a desired end-effector position. This neural network will take as inputs both the desired **end-effector position** as well as the **current joint angles** of the manipulator. The output will be the set of joint angles required to achieve the specified end-effector position.\n",
        "\n",
        "**Input:**\n",
        "- eef_x: x component of the end-effector's position (float)\n",
        "- eef_y: y component of the end-effector's position (float)\n",
        "- q1_current: current theta_1 angle (float)\n",
        "- q2_current: current theta_2 angle (float)\n",
        "\n",
        "**Output:**\n",
        "- q1_next: next theta_1 angle required to achieve (eef_x,eef_y) position (float)\n",
        "- q2_next: next theta_2 angle required to achieve (eef_x,eef_y) position (float)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initiating a 2-Joints Manipulator**\n",
        "\n",
        "The class \"Manipulator\" created was then used to create an instant of a 2 joints model. A sketch of the first manipulator considered can be seen below along with it's DH parameters required to set it up.\n",
        "\n",
        "<img height=\"300px\"  style=\"padding:20px\" src=\"Images/two_joints_manip.jpg\">\n",
        "<img height=\"300px\"  style=\"padding:20px\" src=\"Images/dh_table.jpg\">\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "link1 = Link(theta_offset=0, d=0, alpha=0, a=5)\n",
        "link2 = Link(theta_offset=0, d=0, alpha=0, a=5)\n",
        "\n",
        "manip = Manipulator()\n",
        "manip.add_link(link1)\n",
        "manip.add_link(link2)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Generation Specifications (exporting data):**\n",
        "\n",
        "- Range of q1_next: from 0 to 2pi\n",
        "- Range of q2_next: from 0 to 2pi\n",
        "- Step Size for both q1_next and q2_next: 0.01\n",
        "\n",
        "- q1_current and q2_current will be set to 20 random angles +/- a maximum of 0.005 from q1_next and q2_next respectively"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Note: Can skip this block if file \"two_joints_with_nearby_data.txt\" already in directory)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "q1_next_from = 0\n",
        "q1_next_to = 2*pi\n",
        "q1_next_step_size = 0.01\n",
        "\n",
        "q2_next_from = 0\n",
        "q2_next_to = 2*pi\n",
        "q2_next_step_size = 0.01\n",
        "\n",
        "total_iterations = ((q1_next_to - q1_next_from) / q1_next_step_size + 1) * ((q2_next_to - q2_next_from) / q2_next_step_size + 1)\n",
        "progress_interval = total_iterations // 10 \n",
        "\n",
        "with open('two_joints_with_nearby_data.txt', 'w') as file:\n",
        "    q1_next = q1_next_from\n",
        "    iterations = 0\n",
        "    while q1_next <= q1_next_to:\n",
        "        q2_next = q2_next_from\n",
        "        while q2_next <= q2_next_to:\n",
        "            end_effector_positions = manip.forward_kinematics([q1_next,q2_next])\n",
        "            x = end_effector_positions[0][3]\n",
        "            y = end_effector_positions[1][3]\n",
        "            for i in range(20):\n",
        "                ran = random.uniform(-0.005, 0.005)  \n",
        "                q1_current = q1_next + ran\n",
        "                ran = random.uniform(-0.005, 0.005)  \n",
        "                q2_current = q2_next + ran\n",
        "                file.write(f\"{x} {y} {q1_current} {q2_current} {q1_next} {q2_next} \\n\")\n",
        "            iterations += 1\n",
        "            if iterations % progress_interval == 0:\n",
        "                progress_percent = (iterations / total_iterations) * 100\n",
        "                print(f\"Progress: {progress_percent:.2f}%\")\n",
        "            q2_next = q2_next + q1_next_step_size\n",
        "        q1_next = q1_next + q2_next_step_size\n",
        "print(f\"Progress: 100.00%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 10.00%\n",
            "Progress: 20.00%\n",
            "Progress: 30.00%\n",
            "Progress: 40.00%\n",
            "Progress: 50.00%\n",
            "Progress: 60.00%\n",
            "Progress: 70.00%\n",
            "Progress: 80.00%\n",
            "Progress: 90.00%\n",
            "Progress: 100.00%\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting Data (importing data):**\n",
        "\n",
        "Storing the inputs (eef_x,eef_y,q1_current,q2_current) and outputs (q1_next,q2_next) in the required format"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "eef_x = []\n",
        "eef_y = []\n",
        "q1_current = []\n",
        "q2_current = []\n",
        "\n",
        "q1_next = []\n",
        "q2_next = []\n",
        "\n",
        "with open('two_joints_with_nearby_data.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        data = line.split()\n",
        "        eef_x.append(float(data[0]))\n",
        "        eef_y.append(float(data[1]))\n",
        "        q1_current.append(float(data[2]))\n",
        "        q2_current.append(float(data[3]))\n",
        "        q1_next.append(float(data[4]))\n",
        "        q2_next.append(float(data[5]))\n",
        "\n",
        "eef_x = np.array(eef_x)\n",
        "eef_y = np.array(eef_y)\n",
        "q1_current = np.array(q1_current)\n",
        "q2_current = np.array(q2_current)\n",
        "\n",
        "q1_next = np.array(q1_next)\n",
        "q2_next = np.array(q2_next)\n",
        "\n",
        "print(\"eef_x Shape: \", eef_x.shape)\n",
        "print(\"eef_y Shape: \", eef_y.shape)\n",
        "print(\"q1_current Shape: \", q1_current.shape)\n",
        "print(\"q2_current Shape: \", q2_current.shape)\n",
        "\n",
        "print(\"q1_next Shape: \", q1_next.shape)\n",
        "print(\"q2_next Shape: \", q2_next.shape)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. Necessary Setup**"
      ],
      "metadata": {
        "id": "jddIeJV4gq3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Using cuda GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "uzDGfun2gqWK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "class PosesDataset(Dataset):\n",
        "    def __init__(self, eef_x, eef_y, q1_current, q2_current, q1_next, q2_next):\n",
        "        self.eef_x = torch.tensor(eef_x, dtype=torch.float32)\n",
        "        self.eef_y = torch.tensor(eef_y, dtype=torch.float32)\n",
        "        self.q1_current = torch.tensor(q1_current, dtype=torch.float32)\n",
        "        self.q2_current = torch.tensor(q2_current, dtype=torch.float32)\n",
        "        self.q1_next = torch.tensor(q1_next, dtype=torch.float32)\n",
        "        self.q2_next = torch.tensor(q2_next, dtype=torch.float32)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eef_x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.eef_x[idx],\n",
        "            self.eef_y[idx],\n",
        "            self.q1_current[idx],\n",
        "            self.q2_current[idx],\n",
        "            self.q1_next[idx],\n",
        "            self.q2_next[idx]\n",
        "        )"
      ],
      "outputs": [],
      "metadata": {
        "id": "wzM20ij72iTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "# Initialize dataset\n",
        "dataset = PosesDataset(eef_x, eef_y, q1_current, q2_current, q1_next, q2_next)\n",
        "\n",
        "# Define train/validation split (if needed)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Initialize data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/folders/y_/g46v5wcs2mlg96p8tytg8l7m0000gn/T/ipykernel_34179/3363737747.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.eef_x = torch.tensor(eef_x, dtype=torch.float32)\n",
            "/var/folders/y_/g46v5wcs2mlg96p8tytg8l7m0000gn/T/ipykernel_34179/3363737747.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.eef_y = torch.tensor(eef_y, dtype=torch.float32)\n",
            "/var/folders/y_/g46v5wcs2mlg96p8tytg8l7m0000gn/T/ipykernel_34179/3363737747.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.q1_current = torch.tensor(q1_current, dtype=torch.float32)\n",
            "/var/folders/y_/g46v5wcs2mlg96p8tytg8l7m0000gn/T/ipykernel_34179/3363737747.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.q2_current = torch.tensor(q2_current, dtype=torch.float32)\n",
            "/var/folders/y_/g46v5wcs2mlg96p8tytg8l7m0000gn/T/ipykernel_34179/3363737747.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.q1_next = torch.tensor(q1_next, dtype=torch.float32)\n",
            "/var/folders/y_/g46v5wcs2mlg96p8tytg8l7m0000gn/T/ipykernel_34179/3363737747.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.q2_next = torch.tensor(q2_next, dtype=torch.float32)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "class IKModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IKModel, self).__init__()\n",
        "        # Define your model architecture\n",
        "        # Example:\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 2)  # Output layer for q1_next, q2_next\n",
        "        )\n",
        "    \n",
        "    def forward(self, eef_x, eef_y, q1_current, q2_current):\n",
        "        # Concatenate input features\n",
        "        input_features = torch.cat((eef_x.unsqueeze(1), eef_y.unsqueeze(1), q1_current.unsqueeze(1), q2_current.unsqueeze(1)), dim=1)\n",
        "        \n",
        "        # Forward pass through the model\n",
        "        output = self.fc(input_features)\n",
        "        return output\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqq4iE9Xut3o",
        "outputId": "0af355ff-bbc6-4541-c467-64d22e897033"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "model = IKModel().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "Loss = nn.MSELoss()\n",
        "print(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IKModel(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=16, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9RSXYaggAdw",
        "outputId": "3a4c7a25-3731-40a6-d53b-165e96854ffd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "num_of_epochs = 1\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "test_accuracy_history = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_of_epochs):\n",
        "  train_loss = 0.0\n",
        "  test_loss = 0.0\n",
        "  for i, batch in enumerate(train_loader):\n",
        "    eef_x, eef_y, q1_current, q2_current, q1_next, q2_next = batch\n",
        "    eef_x, eef_y, q1_current, q2_current, q1_next, q2_next = (\n",
        "            eef_x.to(device).float(),\n",
        "            eef_y.to(device).float(),\n",
        "            q1_current.to(device).float(),\n",
        "            q2_current.to(device).float(),\n",
        "            q1_next.to(device).float(),\n",
        "            q2_next.to(device).float(),\n",
        "        )\n",
        "\n",
        "    # Forward Pass\n",
        "    output = model(eef_x, eef_y, q1_current, q2_current)\n",
        "    # Finding Loss\n",
        "    combined_q = torch.cat((q1_next.unsqueeze(1), q2_next.unsqueeze(1)), dim=1)\n",
        "    fit = Loss(output, combined_q)\n",
        "    print(f\"Percentage: {100*i/len(train_loader):.4f}%\")\n",
        "    print(\"Training Loss: \", fit.item()/len(batch))\n",
        "    fit.backward()\n",
        "    # Optimizing Loss\n",
        "    optimizer.zero_grad()\n",
        "    optimizer.step()\n",
        "    train_loss += fit.item()\n",
        "  model.eval()\n",
        "  for i, batch in enumerate(test_loader):\n",
        "    with torch.no_grad():\n",
        "      eef_x, eef_y, q1_current, q2_current, q1_next, q2_next = batch\n",
        "      eef_x, eef_y, q1_current, q2_current, q1_next, q2_next = (\n",
        "              eef_x.to(device).float(),\n",
        "              eef_y.to(device).float(),\n",
        "              q1_current.to(device).float(),\n",
        "              q2_current.to(device).float(),\n",
        "              q1_next.to(device).float(),\n",
        "              q2_next.to(device).float(),\n",
        "          )\n",
        "      # Forward Pass\n",
        "      output = model(eef_x, eef_y, q1_current, q2_current)\n",
        "      # Finding Loss\n",
        "      combined_q = torch.cat((q1_next.unsqueeze(1), q2_next.unsqueeze(1)), dim=1)\n",
        "      fit = Loss(output, combined_q)\n",
        "      # Optimizing Loss\n",
        "      test_loss += fit.item()\n",
        "      print(f\"Percentage: {100*i/len(test_loader):.4f}%\")\n",
        "      print(\"Testing Loss: \", fit.item()/len(batch))\n",
        "  train_loss = train_loss/train_size\n",
        "  test_loss = test_loss/test_size\n",
        "  train_loss_history.append(train_loss)\n",
        "  test_loss_history.append(test_loss)\n",
        "  print(f\"Epoch: {epoch}, Training Loss: {train_loss:.2f}, Training Loss: {train_loss:.4f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage: 0.0000%\n",
            "Training Loss:  1.9175829887390137\n",
            "Percentage: 0.0000%\n",
            "Testing Loss:  2.430558204650879\n",
            "Epoch: 0, Training Loss: 0.41, Training Loss: 0.4109\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(range(30),train_accuracy_history,\"-\",linewidth=3,label=\"Train Error\")\n",
        "plt.plot(range(30),test_accuracy_history,\"-\",linewidth=3,label=\"Test Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WDyqXxtxR2h2",
        "outputId": "a4ff871f-9e88-41a5-9267-163858059c42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "all_predicted = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        output = model(images)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy using all_predicted and test_set.labels\n",
        "accuracy = (np.array(all_predicted) == test_set.labels).mean()\n",
        "print(f\"Model Accuracy: {accuracy*100:.2f}%\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aC2t65d4TEuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "torch.save(model.state_dict(),'drive/MyDrive/Colab-Data/rsp.pt')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VXo0c07PVMxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(model(torch.tensor([0.854494893105,0.98617294483]).to(device)))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d-ea-S9obHl3"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10.9 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "1d051fc57616189bbb3568453e7ae6a09b39d30a7544d80b45e2dc7e0ced0be8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}